{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:34:20.254262Z",
     "iopub.status.busy": "2023-11-26T04:34:20.253728Z",
     "iopub.status.idle": "2023-11-26T04:34:27.906167Z",
     "shell.execute_reply": "2023-11-26T04:34:27.905052Z",
     "shell.execute_reply.started": "2023-11-26T04:34:20.254236Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import torch\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/f7/27/c0faba9135bf3f110810e7e7896233c92edb92827ef824649f08d24adebd/torchvision-0.16.2-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached torchvision-0.16.2-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: torch==2.1.2 in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.2->torchvision) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.2->torchvision) (4.6.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.2->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.2->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.2->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.1.2->torchvision) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch==2.1.2->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch==2.1.2->torchvision) (1.3.0)\n",
      "Using cached torchvision-0.16.2-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.16.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\monis\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: C:\\Users\\monis\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:37:20.055812Z",
     "iopub.status.busy": "2023-11-26T04:37:20.055447Z",
     "iopub.status.idle": "2023-11-26T04:37:23.179583Z",
     "shell.execute_reply": "2023-11-26T04:37:23.178444Z",
     "shell.execute_reply.started": "2023-11-26T04:37:20.055785Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data_dir = 'C:/Monish/New folder/Prj/AIML Lab 7th sem/fruit images'\n",
    "train_dir = data_dir + '/train/train'\n",
    "\n",
    "# Define your transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load all the images from the train folder\n",
    "all_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "\n",
    "# Calculate the sizes for train, validation, and test sets\n",
    "total_size = len(all_data)\n",
    "train_size = int(0.7 * total_size)\n",
    "test_size = int(0.2 * total_size)\n",
    "valid_size = total_size - train_size - test_size\n",
    "\n",
    "# Use random_split to split the dataset\n",
    "train_data, valid_data, test_data = torch.utils.data.random_split(all_data, [train_size, valid_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=50, shuffle=False)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=50)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T13:29:09.526550Z",
     "iopub.status.busy": "2023-11-25T13:29:09.526242Z",
     "iopub.status.idle": "2023-11-25T13:29:09.530788Z",
     "shell.execute_reply": "2023-11-25T13:29:09.529866Z",
     "shell.execute_reply.started": "2023-11-25T13:29:09.526525Z"
    }
   },
   "outputs": [],
   "source": [
    "# image,data = train_data[2]\n",
    "# image = np.transpose(image.numpy(), (1, 2, 0))\n",
    "\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T13:29:09.532460Z",
     "iopub.status.busy": "2023-11-25T13:29:09.532087Z",
     "iopub.status.idle": "2023-11-25T13:29:09.541248Z",
     "shell.execute_reply": "2023-11-25T13:29:09.540336Z",
     "shell.execute_reply.started": "2023-11-25T13:29:09.532428Z"
    }
   },
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T13:29:09.542607Z",
     "iopub.status.busy": "2023-11-25T13:29:09.542363Z",
     "iopub.status.idle": "2023-11-25T13:29:09.551846Z",
     "shell.execute_reply": "2023-11-25T13:29:09.550964Z",
     "shell.execute_reply.started": "2023-11-25T13:29:09.542586Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Note that length of possible outpouts is 102\n",
    "# import json\n",
    "# with open('cat_to_name.json', 'r') as f:\n",
    "#     cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opting for Keras model of the 16-layer network (vgg16) architecture over 13-layer network (vgg13).** [Reference](https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:37:48.552639Z",
     "iopub.status.busy": "2023-11-26T04:37:48.551696Z",
     "iopub.status.idle": "2023-11-26T04:37:50.345864Z",
     "shell.execute_reply": "2023-11-26T04:37:50.344875Z",
     "shell.execute_reply.started": "2023-11-26T04:37:48.552605Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\monis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to C:\\Users\\monis/.cache\\torch\\hub\\checkpoints\\alexnet-owt-7be5be79.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 233M/233M [00:41<00:00, 5.86MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained network \n",
    "model = models.alexnet(pretrained=True)\n",
    "model.name = \"alexnet\"\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:37:54.000526Z",
     "iopub.status.busy": "2023-11-26T04:37:53.999834Z",
     "iopub.status.idle": "2023-11-26T04:37:54.005051Z",
     "shell.execute_reply": "2023-11-26T04:37:54.004121Z",
     "shell.execute_reply.started": "2023-11-26T04:37:54.000473Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:37:55.761699Z",
     "iopub.status.busy": "2023-11-26T04:37:55.761065Z",
     "iopub.status.idle": "2023-11-26T04:37:56.107040Z",
     "shell.execute_reply": "2023-11-26T04:37:56.106213Z",
     "shell.execute_reply.started": "2023-11-26T04:37:55.761660Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a new, untrainted feed-forward network as a classifier, using ReLU activations and dropout\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(9216, 4096, bias=True)),\n",
    "                          ('relu1', nn.ReLU()),\n",
    "                          ('dropout1', nn.Dropout(p=0.5)),\n",
    "                          ('fc2', nn.Linear(4096, 33, bias=True)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:37:58.734818Z",
     "iopub.status.busy": "2023-11-26T04:37:58.734447Z",
     "iopub.status.idle": "2023-11-26T04:37:58.804140Z",
     "shell.execute_reply": "2023-11-26T04:37:58.803197Z",
     "shell.execute_reply.started": "2023-11-26T04:37:58.734790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device agnostic code, automatically uses CUDA if it's enabled\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:38:03.606019Z",
     "iopub.status.busy": "2023-11-26T04:38:03.605628Z",
     "iopub.status.idle": "2023-11-26T04:38:08.090047Z",
     "shell.execute_reply": "2023-11-26T04:38:08.089159Z",
     "shell.execute_reply.started": "2023-11-26T04:38:03.605987Z"
    }
   },
   "outputs": [],
   "source": [
    "# change to device\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:38:53.118627Z",
     "iopub.status.busy": "2023-11-26T04:38:53.117984Z",
     "iopub.status.idle": "2023-11-26T04:38:53.124641Z",
     "shell.execute_reply": "2023-11-26T04:38:53.123494Z",
     "shell.execute_reply.started": "2023-11-26T04:38:53.118581Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Define deep learning method\n",
    "epochs = 5\n",
    "print_every = 30 # Prints every 30 images out of batch of 50 images\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:38:14.951122Z",
     "iopub.status.busy": "2023-11-26T04:38:14.950757Z",
     "iopub.status.idle": "2023-11-26T04:38:14.957794Z",
     "shell.execute_reply": "2023-11-26T04:38:14.956692Z",
     "shell.execute_reply.started": "2023-11-26T04:38:14.951087Z"
    }
   },
   "outputs": [],
   "source": [
    "# Implement a function for the validation pass\n",
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for ii, (inputs, labels) in enumerate(testloader):\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        output = model.forward(inputs)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "        \n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:38:56.049487Z",
     "iopub.status.busy": "2023-11-26T04:38:56.049119Z",
     "iopub.status.idle": "2023-11-26T04:47:30.642952Z",
     "shell.execute_reply": "2023-11-26T04:47:30.642016Z",
     "shell.execute_reply.started": "2023-11-26T04:38:56.049457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training process initializing .....\n",
      "\n",
      "Epoch: 1/5 |  Training Loss: 0.4663 |  Validation Loss: 0.2812 |  Validation Accuracy: 0.9192\n",
      "Epoch: 1/5 |  Training Loss: 0.3258 |  Validation Loss: 0.2252 |  Validation Accuracy: 0.9290\n",
      "Epoch: 1/5 |  Training Loss: 0.2598 |  Validation Loss: 0.2110 |  Validation Accuracy: 0.9357\n",
      "Epoch: 1/5 |  Training Loss: 0.2333 |  Validation Loss: 0.2214 |  Validation Accuracy: 0.9282\n",
      "Epoch: 1/5 |  Training Loss: 0.2394 |  Validation Loss: 0.1388 |  Validation Accuracy: 0.9565\n",
      "Epoch: 1/5 |  Training Loss: 0.2780 |  Validation Loss: 0.2048 |  Validation Accuracy: 0.9292\n",
      "Epoch: 1/5 |  Training Loss: 0.2693 |  Validation Loss: 0.2057 |  Validation Accuracy: 0.9394\n",
      "Epoch: 2/5 |  Training Loss: 0.0355 |  Validation Loss: 0.1682 |  Validation Accuracy: 0.9484\n",
      "Epoch: 2/5 |  Training Loss: 0.2767 |  Validation Loss: 0.1312 |  Validation Accuracy: 0.9608\n",
      "Epoch: 2/5 |  Training Loss: 0.3010 |  Validation Loss: 0.1899 |  Validation Accuracy: 0.9512\n",
      "Epoch: 2/5 |  Training Loss: 0.3619 |  Validation Loss: 0.1831 |  Validation Accuracy: 0.9439\n",
      "Epoch: 2/5 |  Training Loss: 0.3149 |  Validation Loss: 0.1835 |  Validation Accuracy: 0.9516\n",
      "Epoch: 2/5 |  Training Loss: 0.2616 |  Validation Loss: 0.1354 |  Validation Accuracy: 0.9619\n",
      "Epoch: 2/5 |  Training Loss: 0.2327 |  Validation Loss: 0.1026 |  Validation Accuracy: 0.9694\n",
      "Epoch: 2/5 |  Training Loss: 0.2762 |  Validation Loss: 0.2260 |  Validation Accuracy: 0.9445\n",
      "Epoch: 3/5 |  Training Loss: 0.0641 |  Validation Loss: 0.1435 |  Validation Accuracy: 0.9588\n",
      "Epoch: 3/5 |  Training Loss: 0.3824 |  Validation Loss: 0.1033 |  Validation Accuracy: 0.9682\n",
      "Epoch: 3/5 |  Training Loss: 0.2786 |  Validation Loss: 0.1077 |  Validation Accuracy: 0.9669\n",
      "Epoch: 3/5 |  Training Loss: 0.3084 |  Validation Loss: 0.1273 |  Validation Accuracy: 0.9559\n",
      "Epoch: 3/5 |  Training Loss: 0.2877 |  Validation Loss: 0.1542 |  Validation Accuracy: 0.9557\n",
      "Epoch: 3/5 |  Training Loss: 0.3210 |  Validation Loss: 0.1199 |  Validation Accuracy: 0.9657\n",
      "Epoch: 3/5 |  Training Loss: 0.1781 |  Validation Loss: 0.0900 |  Validation Accuracy: 0.9706\n",
      "Epoch: 3/5 |  Training Loss: 0.2511 |  Validation Loss: 0.1102 |  Validation Accuracy: 0.9719\n",
      "Epoch: 4/5 |  Training Loss: 0.0997 |  Validation Loss: 0.1900 |  Validation Accuracy: 0.9494\n",
      "Epoch: 4/5 |  Training Loss: 0.2979 |  Validation Loss: 0.1116 |  Validation Accuracy: 0.9690\n",
      "Epoch: 4/5 |  Training Loss: 0.2319 |  Validation Loss: 0.1161 |  Validation Accuracy: 0.9680\n",
      "Epoch: 4/5 |  Training Loss: 0.1926 |  Validation Loss: 0.0953 |  Validation Accuracy: 0.9696\n",
      "Epoch: 4/5 |  Training Loss: 0.1834 |  Validation Loss: 0.0919 |  Validation Accuracy: 0.9712\n",
      "Epoch: 4/5 |  Training Loss: 0.1803 |  Validation Loss: 0.0892 |  Validation Accuracy: 0.9747\n",
      "Epoch: 4/5 |  Training Loss: 0.1822 |  Validation Loss: 0.1063 |  Validation Accuracy: 0.9712\n",
      "Epoch: 4/5 |  Training Loss: 0.2508 |  Validation Loss: 0.1538 |  Validation Accuracy: 0.9594\n",
      "Epoch: 5/5 |  Training Loss: 0.1217 |  Validation Loss: 0.1679 |  Validation Accuracy: 0.9629\n",
      "Epoch: 5/5 |  Training Loss: 0.1877 |  Validation Loss: 0.1023 |  Validation Accuracy: 0.9721\n",
      "Epoch: 5/5 |  Training Loss: 0.1716 |  Validation Loss: 0.1265 |  Validation Accuracy: 0.9674\n",
      "Epoch: 5/5 |  Training Loss: 0.3036 |  Validation Loss: 0.1177 |  Validation Accuracy: 0.9716\n",
      "Epoch: 5/5 |  Training Loss: 0.2068 |  Validation Loss: 0.0795 |  Validation Accuracy: 0.9757\n",
      "Epoch: 5/5 |  Training Loss: 0.2835 |  Validation Loss: 0.1385 |  Validation Accuracy: 0.9618\n",
      "Epoch: 5/5 |  Training Loss: 0.2434 |  Validation Loss: 0.0941 |  Validation Accuracy: 0.9733\n",
      "Epoch: 5/5 |  Training Loss: 0.2594 |  Validation Loss: 0.0881 |  Validation Accuracy: 0.9806\n",
      "\n",
      "Training process is now complete!!\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier layers using backpropogation using the pre-trained network to get features\n",
    "\n",
    "print(\"Training process initializing .....\\n\")\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    model.train() # Technically not necessary, setting this for good measure\n",
    "    \n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_loss, accuracy = validation(model, validloader, criterion)\n",
    "            \n",
    "            print(\"Epoch: {}/{} | \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.4f} | \".format(running_loss/print_every),\n",
    "                  \"Validation Loss: {:.4f} | \".format(valid_loss/len(validloader)),\n",
    "                  \"Validation Accuracy: {:.4f}\".format(accuracy/len(validloader)))\n",
    "            \n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n",
    "print(\"\\nTraining process is now complete!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your network\n",
    "\n",
    "It's good practice to test your trained network on test data, images the network has never seen either in training or validation. This will give you a good estimate for the model's performance on completely new images. Run the test images through the network and measure the accuracy, the same way you did validation. You should be able to reach around 70% accuracy on the test set if the model has been trained well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:47:59.844530Z",
     "iopub.status.busy": "2023-11-26T04:47:59.844144Z",
     "iopub.status.idle": "2023-11-26T04:47:59.849331Z",
     "shell.execute_reply": "2023-11-26T04:47:59.848222Z",
     "shell.execute_reply.started": "2023-11-26T04:47:59.844489Z"
    }
   },
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_predictions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to load all image tensors to gpu before the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:48:08.050705Z",
     "iopub.status.busy": "2023-11-26T04:48:08.049737Z",
     "iopub.status.idle": "2023-11-26T04:48:37.624111Z",
     "shell.execute_reply": "2023-11-26T04:48:37.623136Z",
     "shell.execute_reply.started": "2023-11-26T04:48:08.050663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  87.8890392780304\n",
      "Accuracy achieved by the network on test images is: 97%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Do validation on the test set\n",
    "# Do validation on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        all_labels.extend(labels.numpy())\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        predicted_tensor_cpu = predicted.to('cpu')\n",
    "        all_predictions.extend(predicted_tensor_cpu.numpy())\n",
    "\n",
    "print('Accuracy achieved by the network on test images is: %d%%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:48:37.632990Z",
     "iopub.status.busy": "2023-11-26T04:48:37.632700Z",
     "iopub.status.idle": "2023-11-26T04:48:37.646361Z",
     "shell.execute_reply": "2023-11-26T04:48:37.645367Z",
     "shell.execute_reply.started": "2023-11-26T04:48:37.632965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3370\n"
     ]
    }
   ],
   "source": [
    "print(len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:48:45.897385Z",
     "iopub.status.busy": "2023-11-26T04:48:45.897014Z",
     "iopub.status.idle": "2023-11-26T04:48:45.902301Z",
     "shell.execute_reply": "2023-11-26T04:48:45.901274Z",
     "shell.execute_reply.started": "2023-11-26T04:48:45.897357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3370\n"
     ]
    }
   ],
   "source": [
    "print(len(all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:48:48.808816Z",
     "iopub.status.busy": "2023-11-26T04:48:48.808175Z",
     "iopub.status.idle": "2023-11-26T04:48:49.099038Z",
     "shell.execute_reply": "2023-11-26T04:48:49.098056Z",
     "shell.execute_reply.started": "2023-11-26T04:48:48.808784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 91   0   0 ...   0   0   0]\n",
      " [  0 104   0 ...   0   0   0]\n",
      " [  0   0 104 ...   0   2   0]\n",
      " ...\n",
      " [  0   0   0 ... 107   0   0]\n",
      " [  0   0   0 ...   0 154   0]\n",
      " [  0   0   0 ...   0   0  72]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "all_labels = np.array(all_labels)\n",
    "all_predictions = np.array(all_predictions)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:48:52.656280Z",
     "iopub.status.busy": "2023-11-26T04:48:52.655527Z",
     "iopub.status.idle": "2023-11-26T04:48:52.679139Z",
     "shell.execute_reply": "2023-11-26T04:48:52.678169Z",
     "shell.execute_reply.started": "2023-11-26T04:48:52.656247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90        94\n",
      "           1       0.91      1.00      0.95       104\n",
      "           2       0.97      0.98      0.98       106\n",
      "           3       0.99      1.00      0.99        94\n",
      "           4       0.99      0.94      0.96        96\n",
      "           5       1.00      0.98      0.99       110\n",
      "           6       0.99      0.99      0.99        95\n",
      "           7       0.99      1.00      0.99        89\n",
      "           8       0.96      1.00      0.98        89\n",
      "           9       1.00      1.00      1.00       103\n",
      "          10       1.00      0.96      0.98        81\n",
      "          11       0.99      1.00      0.99        79\n",
      "          12       0.99      0.99      0.99       199\n",
      "          13       1.00      0.98      0.99        92\n",
      "          14       0.97      1.00      0.99        99\n",
      "          15       1.00      0.97      0.98        92\n",
      "          16       1.00      0.95      0.98       105\n",
      "          17       0.97      0.99      0.98        87\n",
      "          18       0.98      1.00      0.99        84\n",
      "          19       0.90      0.94      0.92       108\n",
      "          20       0.98      1.00      0.99       111\n",
      "          21       1.00      0.72      0.84       121\n",
      "          22       0.95      0.99      0.97       134\n",
      "          23       1.00      1.00      1.00        87\n",
      "          24       1.00      0.96      0.98       121\n",
      "          25       1.00      1.00      1.00        89\n",
      "          26       1.00      0.96      0.98        93\n",
      "          27       0.93      0.97      0.95       101\n",
      "          28       1.00      0.99      0.99        80\n",
      "          29       1.00      1.00      1.00        92\n",
      "          30       0.99      0.98      0.99       109\n",
      "          31       0.94      1.00      0.97       154\n",
      "          32       1.00      1.00      1.00        72\n",
      "\n",
      "    accuracy                           0.97      3370\n",
      "   macro avg       0.98      0.98      0.98      3370\n",
      "weighted avg       0.98      0.97      0.97      3370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(all_labels, all_predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the checkpoint\n",
    "\n",
    "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n",
    "\n",
    "```model.class_to_idx = image_datasets['train'].class_to_idx```\n",
    "\n",
    "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Create a checkpoint [Reference](https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:48:58.968543Z",
     "iopub.status.busy": "2023-11-26T04:48:58.968223Z",
     "iopub.status.idle": "2023-11-26T04:48:58.973289Z",
     "shell.execute_reply": "2023-11-26T04:48:58.972356Z",
     "shell.execute_reply.started": "2023-11-26T04:48:58.968519Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming your train_data is a Subset object\n",
    "original_dataset = train_data.dataset\n",
    "\n",
    "# Create a class_to_idx mapping\n",
    "model.class_to_idx = {class_name: idx for idx, class_name in enumerate(original_dataset.classes)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:49:01.528785Z",
     "iopub.status.busy": "2023-11-26T04:49:01.527875Z",
     "iopub.status.idle": "2023-11-26T04:49:01.533405Z",
     "shell.execute_reply": "2023-11-26T04:49:01.532279Z",
     "shell.execute_reply.started": "2023-11-26T04:49:01.528751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple Braeburn': 0, 'Apple Granny Smith': 1, 'Apricot': 2, 'Avocado': 3, 'Banana': 4, 'Blueberry': 5, 'Cactus fruit': 6, 'Cantaloupe': 7, 'Cherry': 8, 'Clementine': 9, 'Corn': 10, 'Cucumber Ripe': 11, 'Grape Blue': 12, 'Kiwi': 13, 'Lemon': 14, 'Limes': 15, 'Mango': 16, 'Onion White': 17, 'Orange': 18, 'Papaya': 19, 'Passion Fruit': 20, 'Peach': 21, 'Pear': 22, 'Pepper Green': 23, 'Pepper Red': 24, 'Pineapple': 25, 'Plum': 26, 'Pomegranate': 27, 'Potato Red': 28, 'Raspberry': 29, 'Strawberry': 30, 'Tomato': 31, 'Watermelon': 32}\n"
     ]
    }
   ],
   "source": [
    "print(model.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T04:49:04.189605Z",
     "iopub.status.busy": "2023-11-26T04:49:04.188361Z",
     "iopub.status.idle": "2023-11-26T04:49:04.513281Z",
     "shell.execute_reply": "2023-11-26T04:49:04.512458Z",
     "shell.execute_reply.started": "2023-11-26T04:49:04.189559Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = {'architecture': model.name,\n",
    "             'classifier': model.classifier,\n",
    "             'class_to_idx': model.class_to_idx,\n",
    "             'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3917752,
     "sourceId": 6810129,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
